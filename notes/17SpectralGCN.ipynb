{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbeb7ef6",
   "metadata": {},
   "source": [
    "# spectral graph convolutional network (GCN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "106fb635",
   "metadata": {},
   "source": [
    "Spectral Graph Convolutional Networks (Spectral GCNs) are a class of Graph Neural Networks (GNNs) that perform graph convolutions in the spectral domain. \n",
    "\n",
    "They rely on graph spectral theory, which uses the graph Laplacian and its eigenvalue decomposition to analyze graphs.\n",
    "\n",
    "Spectral GCNs define graph convolutions as the multiplication of the node feature matrix with a **spectral filter**. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86cdcd64",
   "metadata": {},
   "source": [
    "# vertex-domain localization vs. frequency-domain smoothness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ba1673b",
   "metadata": {},
   "source": [
    "smoothness of a graph signal is determined by its relationship with the graph Laplacian eigenvalues. \n",
    "\n",
    "\n",
    "if a graph signal is smooth (slowly varying) in the vertex (spatial) domain, it is associated with lower graph Laplacian eigenvalue, it will be localized in the frequency (spectral) domain, meaning they have most of their energy concentrated in the lower frequencies of the spectral domain.\n",
    "\n",
    "Conversely, if a signal is localized in the spatial domain (i.e., it has sharp changes or rapid variations), it is associated with higher graph Laplacian eigenvalue, it tends to be smooth (spread out) in the spectral domain, with its energy distributed across a wider range of frequencies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0ac5f63",
   "metadata": {},
   "source": [
    "# signal processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2f669e5",
   "metadata": {},
   "source": [
    "## classical signal processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b3453f9",
   "metadata": {},
   "source": [
    "### Fourier transform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ee0b512",
   "metadata": {},
   "source": [
    "Fourier domain: also known as frequency domain or spectral domain, is a representation of a signal or function in terms of its frequency components. \n",
    "\n",
    "Fourier domain is obtained by applying the Fourier Transform (for continuous signals) or the Discrete Fourier Transform (for discrete signals) to the time-domain signal, \n",
    "\n",
    "Fourier Transform decomposes a signal into a sum of sinusoidal functions (sines and cosines) with different frequencies, amplitudes, and phases. \n",
    "\n",
    "Fourier Transform provides an alternative view of a signal's behavior in the frequency domain, highlighting its global frequency characteristics instead of its time or spatial characteristics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe98d59d",
   "metadata": {},
   "source": [
    "Fourier domain representation is essential for \n",
    "\n",
    "- analyze properties of signals or functions\n",
    "\n",
    "- design signal processing techniques: such as filtering, compression, and denoising."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cc922f9",
   "metadata": {},
   "source": [
    "### wavelet transform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d5811ac",
   "metadata": {},
   "source": [
    "- wavelet transform is an operation that decomposes a signal into a set of wavelet coefficients using wavelet basis functions\n",
    "\n",
    "- wavelet coefficients: components of the wavelet-transformed signal that represent the signal's local time-frequency characteristics at different scales. \n",
    "\n",
    "- A wavelet is a mathematical function used as a basis function in wavelet analysis.\n",
    "\n",
    "- main advantage of wavelet transform is their ability to provide multi-scale, localized analysis, which makes them particularly useful for processing signals with non-uniform or transient features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06ecf308",
   "metadata": {},
   "source": [
    "## graph signal processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68e4f0bb",
   "metadata": {},
   "source": [
    "### Graph Fourier transform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1dc237dd",
   "metadata": {},
   "source": [
    "Fourier domain: spectral representation of graph signals, which are functions defined on the vertices of a graph. \n",
    "\n",
    "Fourier domain is obtained by appling Graph Fourier Transform (GFT) to graph signals in the vertex (spatial) domain.\n",
    "\n",
    "The GFT relies on the graph Laplacian's eigenvalue decomposition, where eigenvectors form the graph's Fourier basis/spectrum, and the eigenvalues correspond to graph frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a166f",
   "metadata": {},
   "source": [
    "$$\n",
    "X' = g_{\\theta} (L)X = g_{\\theta} (U\\Lambda U^T)X = U g_{\\theta} (\\Lambda) U^T X\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b2052",
   "metadata": {},
   "source": [
    "1. Graph Fourier Transform (GFT) to the node feature matrix in the spatial domain:\n",
    "   \n",
    "   $$X_{\\text{spectral}} = U^T X_{\\text{spatial}}$$\n",
    "\n",
    "2. Apply GFT filter in the spectral domain:\n",
    "   \n",
    "   $$X_{\\text{filtered}} = g_\\theta(\\Lambda) \\odot X_{\\text{spectral}}$$\n",
    "\n",
    "3. Inverse Graph Fourier Transform (Inverse GFT) to obtain the transformed node features in the spatial domain:\n",
    "\n",
    "   $$X'_{\\text{spatial}} = U X_{\\text{filtered}}$$\n",
    "\n",
    "   $X$ is the node feature matrix in the spatial domain\n",
    "\n",
    "   $L = D - A$ is graph Laplacian matrix, where $D$ is the degree matrix and $A$ is the adjacency matrix.\n",
    "\n",
    "   $U$ is the eigenvector matrix of the graph Laplacian\n",
    "\n",
    "   $\\Lambda$ is the eigenvalue matrix of the graph Laplacian\n",
    "\n",
    "   $g_\\theta(\\Lambda)$ is the GFT filter function\n",
    "\n",
    "   $\\odot$ denotes element-wise multiplication"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0335b158",
   "metadata": {},
   "source": [
    "### graph wavelet transform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8d17354",
   "metadata": {},
   "source": [
    "$$\n",
    "X' = \\psi_s (L)X = \\psi_sg_{\\theta} (U\\Lambda U^T)X = U \\psi_s (\\Lambda) U^T X\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "543c5e89",
   "metadata": {},
   "source": [
    "1. Define graph wavelet function in the spectral domain: which captures the desired time-frequency characteristics, where $s$ is the scale parameter.\n",
    "\n",
    "    $$\\psi_s(x) = e^{-\\frac{x^2}{2s^2}}$$\n",
    "\n",
    "2. Compute graph Laplacian: where $D$ is the degree matrix and $A$ is the adjacency matrix.\n",
    "\n",
    "    $$L = D - A$$\n",
    "\n",
    "3. Compute eigendecomposition of graph Laplacian: $$L = U \\Lambda U^T$$ where $U$ is the matrix of eigenvectors and $\\Lambda$ is the diagonal matrix of eigenvalues.\n",
    "\n",
    "4. Wavelet Transform: $$X' = U \\psi_s(\\Lambda) U^T X$$\n",
    "\n",
    "    where $X$ is the node feature matrix in spatial domain.\n",
    "\n",
    "    $X'$ is transformed signal in spectral domain.\n",
    "\n",
    "    $\\psi_s(\\Lambda)$ is the diagonal matrix formed by applying the wavelet function element-wise to the eigenvalues in $\\Lambda$.\n",
    "\n",
    "5. Inverse Wavelet Transform: $$X = U \\psi_s^{-1}(\\Lambda) U^T X'$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0eba0124",
   "metadata": {},
   "source": [
    "# spectral filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5019e42",
   "metadata": {},
   "source": [
    "spectral filter is a function of graph Laplacian's eigenvalues, denoted as $g_\\theta(\\Lambda)$, where $\\theta$ are the trainable parameters, and $\\Lambda$ is the eigenvalue matrix of the graph Laplacian. \n",
    "\n",
    "The spectral filter operates on the graph Fourier basis, and different types of filters can be used to capture various graph properties. \n",
    "\n",
    "- GFT filter: computational inefficient and global\n",
    "\n",
    "- polynomial filters: computational efficient and localized\n",
    "\n",
    "- wavelet filter: computational inefficient and localized\n",
    "\n",
    "- diffusion filter: computational efficient"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e591af40",
   "metadata": {},
   "source": [
    "## GFT filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c506b9ee",
   "metadata": {},
   "source": [
    "**Directly applying GFT filters in GCN can be computationally expensive** due to several factors:\n",
    "\n",
    "- Eigenvalue decomposition of graph Laplacian: time complexity of $O(n^3)$ for an n x n matrix, which can be quite expensive for large graphs.\n",
    "\n",
    "- Multiplication with eigenvectors: multiplying the node feature matrix with the eigenvector matrix $U$ and its transpose $U^T$ involves two matrix multiplications, each with a time complexity of $O(n^2f)$ for an $n x f$ matrix, where $f$ is the number of features. \n",
    "\n",
    "    This can also become computationally expensive for large graphs with many nodes and features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a1c0323",
   "metadata": {},
   "source": [
    "**GFT filter is a global operation**, can't capture local structure in signals\n",
    "\n",
    "- the filter is applied in the spectral domain based on global frequency characteristics of the graph which represent the entire graph structure, not just the local neighborhood of each vertex."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "796106a9",
   "metadata": {},
   "source": [
    "## polynomial filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "482b227b",
   "metadata": {},
   "source": [
    "Polynomial filters are called approximations because they approximate spectral filters, which can be computationally expensive or difficult to work with due to their global nature or non-localized operations.\n",
    "\n",
    "Polynomial filters are more computationally efficient and localized filter while preserving the key characteristics of the original filter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e6bd117",
   "metadata": {},
   "source": [
    "\n",
    "Polynomial filters are constructed as a linear combination of basis functions\n",
    "\n",
    "$$\n",
    "g_{\\theta} (\\Lambda)  = \\sum_{k=0}^{K-1}\\theta_k \\Lambda ^k\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3a45b66",
   "metadata": {},
   "source": [
    "### localization and smoothness of filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e627911",
   "metadata": {},
   "source": [
    "localization of filter can be controlled by the order (K) of polynomial\n",
    "\n",
    "- order determines the number of coefficients and, consequently, the degree of localization. (K coefficients gives K-node localization)\n",
    "\n",
    "- A lower-order polynomial filter will be smoother in the frequency domain and more localized in the vertex domain. This means that the filter will focus more on the local structure of the signal, capturing patterns and features present in the immediate neighborhood of each vertex. However, a lower-order filter may not be able to capture more complex or global patterns in the graph.\n",
    "\n",
    "- a higher-order polynomial filter will be less smooth in the frequency domain and less localized in the vertex domain. This filter can capture more global patterns and structures in the graph but may lose some of the local information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "abe22206",
   "metadata": {},
   "source": [
    "smoothness of filter can be controlled by Coefficients of the polynomial filter\n",
    "\n",
    "- coefficients determine the weights of the different polynomial terms in the filter.\n",
    "\n",
    "- coefficients are parameters learned during training to best capture the graph's underlying structure and patterns."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "011811f1",
   "metadata": {},
   "source": [
    "### advantage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aaa63f59",
   "metadata": {},
   "source": [
    "Computational efficiency: no explicit eigendecomposition, instead operate directly on the graph Laplacian or the normalized adjacency matrix, making them suitable for large-scale graphs and real-time processing.\n",
    "\n",
    "Vertex-domain localization: Polynomial filters can capture local structure in the graph while preserving essential frequency characteristics, enabling GCN to learn both local and global graph patterns.\n",
    "\n",
    "Flexibility: **smoothness and localization of polynomial filters can be controlled by adjusting order and coefficients**, allowing for a trade-off between accuracy and computational complexity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35ba04f6",
   "metadata": {},
   "source": [
    "### Chebyshev filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddfbc798",
   "metadata": {},
   "source": [
    "Chebyshev filter use Chebyshev polynomials as basis functions to approximate the ideal spectral filter. \n",
    "\n",
    "ChebNet, a popular Spectral GCN, applies Chebyshev filters to the graph Laplacian."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33494cc5",
   "metadata": {},
   "source": [
    "$$\n",
    "g_{\\theta} (\\Lambda)  = \\sum_{k=0}^{K-1}\\theta_k T_k (\\tilde \\Lambda)\n",
    "$$\n",
    "\n",
    "$g_\\theta(\\Lambda)$ represents the Chebyshev filter\n",
    "\n",
    "$T_k$ is the Chebyshev polynomial of order $k$\n",
    "\n",
    "$\\tilde{\\Lambda}$ is the scaled eigenvalue matrix of the graph Laplacian\n",
    "\n",
    "$\\theta_k$ are the trainable parameters\n",
    "\n",
    "$K$: order or degree of the polynomial. $K$ coefficients gives $K$-node localization in vertex domain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b67e941f",
   "metadata": {},
   "source": [
    "Chebyshev polynomials (Chebyshev basis)\n",
    "\n",
    "- defined recursively\n",
    "\n",
    "$$\n",
    "T_k(X):= \\left\\{\\begin{matrix}\n",
    "1 & k=0  \\\\\n",
    "X & k=1 \\\\\n",
    "2yT_{k-1}(X) - T_{k-2}(X) & k \\geq 2  \\\\\n",
    "\\end{matrix}\\right.\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c258f38",
   "metadata": {},
   "source": [
    "- a set of orthogonal polynomials, that form a basis for the space of continuous functions on a specific interval, usually [-1, 1]. \n",
    "\n",
    "- have unique properties, making them useful for approximating functions, solving differential equations, and performing spectral analysis on graphs.\n",
    "\n",
    "    Orthogonality: Chebyshev polynomials are orthogonal with respect to the weight function $w(x) = \\frac{1}{\\sqrt{1-x^2}}$ on the interval [-1, 1]:\n",
    "\n",
    "    $$\\int_{-1}^{1} w(x)T_m(x)T_n(x) dx = \\begin{cases}\n",
    "                                         0 & \\text{if } m \\neq n \\\\\n",
    "                                         \\pi & \\text{if } m = n = 0 \\\\\n",
    "                                         \\frac{\\pi}{2} & \\text{if } m = n \\neq 0\n",
    "                                     \\end{cases}$$\n",
    "\n",
    "    Trigonometric relation: Chebyshev polynomials can be expressed using trigonometric functions:\n",
    "\n",
    "    $$T_n(\\cos(\\theta)) = \\cos(n\\theta)$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ab1e9e4",
   "metadata": {},
   "source": [
    "## wavelet filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b65e84c4",
   "metadata": {},
   "source": [
    "Pros:\n",
    "\n",
    "- Multi-scale analysis: Wavelet filters capture information at different scales, enabling GNNs to analyze and learn hierarchical features.\n",
    "\n",
    "- Localization: Wavelet filters provide localized analysis in both vertex and frequency domains, effectively capturing local structure and patterns.\n",
    "\n",
    "- Adaptability: Graph wavelets can be designed to adapt to graph-specific characteristics, making them suitable for various problems and datasets.\n",
    "\n",
    "Cons:\n",
    "\n",
    "- Complexity: eigendecomposition of graph Laplacian limiting their applicability in large-scale or real-time graph processing scenarios."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76dd4a0c",
   "metadata": {},
   "source": [
    "## diffusion filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2153963a",
   "metadata": {},
   "source": [
    "Diffusion wavelets are a wavelet-based approach designed to work with the diffusion process on graphs. \n",
    "\n",
    "They do not involve eigendecomposition because they are built on the diffusion operator, which directly captures the graph's connectivity structure and allows for localized and multiscale analysis of the graph signal."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98e9c81c",
   "metadata": {},
   "source": [
    "1. Define diffusion operator: $P = \\frac{1}{2}(I + AD^{-1})$, where $A$ is the adjacency matrix, $D$ is the degree matrix, and $I$ is the identity matrix.\n",
    "\n",
    "2. Compute powers of diffusion operator: $\\Psi_j = P^{2^{j-1}} - P^{2^{j}}$, where $j$ is the scale level.\n",
    "\n",
    "3. Diffusion Wavelet Transform: $W_{j} = \\Psi_{j} X$, where $X$ is the node feature matrix.\n",
    "\n",
    "4. Inverse Diffusion Wavelet Transform: $X = \\sum_{j=0}^{J-1} \\Psi_{j}^{-1} W_{j}$, where $J$ is the maximum scale level.\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
